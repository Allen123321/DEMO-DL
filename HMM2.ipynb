{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HMM2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP866xuqcYfjpMLGNXAN6Bj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Allen123321/DEMO-DL/blob/master/HMM2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww0tMHts088Z"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "infinite = float(-2 ** 31)\n",
        "\n",
        "\n",
        "def log_sum_exp(a):\n",
        "    \"\"\"\n",
        "    可以参考numpy中的log sum exp的API\n",
        "    scipy.misc.logsumexp\n",
        "    :param a:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    a = np.asarray(a)\n",
        "    a_max = max(a)\n",
        "    tmp = 0\n",
        "    for k in a:\n",
        "        tmp += math.exp(k - a_max)\n",
        "    return a_max + math.log(tmp)\n",
        "\n",
        "\n",
        "def convert_obs_seq_2_index(Q, index=None):\n",
        "    \"\"\"\n",
        "    将观测序列转换为观测值的索引值\n",
        "    Q:是输入的观测序列\n",
        "    \"\"\"\n",
        "    if index is not None:\n",
        "        cht = Q[index]\n",
        "        if \"黑\" == cht:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    else:\n",
        "        result = []\n",
        "        for q in Q:\n",
        "            if \"黑\" == q:\n",
        "                result.append(1)\n",
        "            else:\n",
        "                result.append(0)\n",
        "        return result\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJQRFuEg1bzl"
      },
      "source": [
        "import numpy as np\n",
        "def calc_alpha(pi, A, B, Q, alpha, fetch_index_by_obs_seq=None):\n",
        "    \"\"\"\n",
        "    计算前向概率α的值\n",
        "    :param pi: 初始的状态随机概率矩阵, n*1 => 经过对数转换\n",
        "    :param A:  状态转移矩阵, n*n => 经过对数转换\n",
        "    :param B:  状态和观测值之间的转移矩阵, n*m => 经过对数转换\n",
        "    :param Q:  观测值序列, 长度为T\n",
        "    :param alpha:  前向概率矩阵\n",
        "    :param fetch_index_by_obs_seq: 根据序列获取对应的索引值，可以为None；是一个接受两个参数的函数，第一个参数为序列，第二个参数为索引值\n",
        "    :return:  返回alpha矩阵同时也更新传入的alpha矩阵参数\n",
        "    \"\"\"\n",
        "    # 1. 初始化\n",
        "    fetch_index_by_obs_seq_f = fetch_index_by_obs_seq\n",
        "    if fetch_index_by_obs_seq_f is None:\n",
        "        # 默认是使用ord函数将对应位置的字符转换为ASCII码，eg: ord('a')=97; ord('中')=20013\n",
        "        fetch_index_by_obs_seq_f = lambda obs, obs_index: ord(obs[obs_index])\n",
        "\n",
        "    # 2. 获取相关变量\n",
        "    n = np.shape(A)[0]\n",
        "    T = len(Q)\n",
        "\n",
        "    # 3. 更新t=1时刻(初始时刻)对应的前向概率值\n",
        "    for i in range(n):\n",
        "        alpha[0][i] = pi[i] + B[i][fetch_index_by_obs_seq_f(Q, 0)]\n",
        "\n",
        "    # 4. 更新t=2,3....T时刻对应的前向概率值\n",
        "    tmp = [0 for i in range(n)]\n",
        "    for t in range(1, T):\n",
        "        # TODO: 开始更新时刻t、状态为i的前向概率值\n",
        "        for i in range(n):\n",
        "            # 4.1. 计算累加值\n",
        "            for j in range(n):\n",
        "                tmp[j] = alpha[t - 1][j] + A[j][i]\n",
        "\n",
        "            # 4.2. 计算log_sum_exp的值\n",
        "            alpha[t][i] = log_sum_exp(tmp)\n",
        "\n",
        "            # 4.3. 累加状态和观测值之间的转移矩阵\n",
        "            alpha[t][i] += B[i][fetch_index_by_obs_seq_f(Q, t)]\n",
        "\n",
        "    # 5. 返回最终返回值\n",
        "    return alpha\n",
        "\n",
        "\n",
        "def calc_beta(pi, A, B, Q, beta, fetch_index_by_obs_seq=None):\n",
        "    \"\"\"\n",
        "    计算后向概率β的值\n",
        "    :param pi: 初始的状态随机概率矩阵, n*1 => 经过对数转换\n",
        "    :param A:  状态转移矩阵, n*n => 经过对数转换\n",
        "    :param B:  状态和观测值之间的转移矩阵, n*m => 经过对数转换\n",
        "    :param Q:  观测值序列, 长度为T\n",
        "    :param beta: 后向概率矩阵\n",
        "    :param fetch_index_by_obs_seq: 根据序列获取对应的索引值，可以为None；是一个接受两个参数的函数，第一个参数为序列，第二个参数为索引值\n",
        "    :return:  返回beta矩阵同时也更新传入的beta矩阵参数\n",
        "    \"\"\"\n",
        "    # 1. 初始化\n",
        "    fetch_index_by_obs_seq_f = fetch_index_by_obs_seq\n",
        "    if fetch_index_by_obs_seq_f is None:\n",
        "        # 默认是使用ord函数将对应位置的字符转换为ASCII码，eg: ord('a')=97; ord('中')=20013\n",
        "        fetch_index_by_obs_seq_f = lambda obs, obs_index: ord(obs[obs_index])\n",
        "\n",
        "    # 2. 获取相关变量\n",
        "    n = np.shape(A)[0]\n",
        "    T = len(Q)\n",
        "\n",
        "    # 3. 更新t=T时刻(初始时刻)对应的后向概率值\n",
        "    for i in range(n):\n",
        "        beta[T - 1][i] = 0\n",
        "\n",
        "    # 4. 更新t=T-1,T-2....1时刻对应的前向概率值\n",
        "    tmp = [0 for i in range(n)]\n",
        "    for t in range(T - 2, -1, -1):\n",
        "        # TODO: 更新时刻t对应状态为i的后向概率\n",
        "        for i in range(n):\n",
        "            # 4.1 计算累加值\n",
        "            for j in range(n):\n",
        "                tmp[j] = A[i][j] + beta[t + 1][j] + B[j][fetch_index_by_obs_seq_f(Q, t + 1)]\n",
        "\n",
        "            # 4.2 计算log_sum_exp的值\n",
        "            beta[t][i] = log_sum_exp(tmp)\n",
        "\n",
        "    # 5. 结果返回\n",
        "    return beta\n",
        "\n",
        "\n",
        "def calc_gamma(alpha, beta, gamma):\n",
        "    \"\"\"\n",
        "    根据alphe和beta的值计算gamma值\n",
        "    最终结果保存在gamma矩阵中\n",
        "    :param alpha: 传入的alpha矩阵 => 经过log转换后的\n",
        "    :param beta:  传入的beta矩阵 => 经过log转换后的\n",
        "    :param gamma: 传入的gamma矩阵，需要进行更新，最终结果是经过log转换后的\n",
        "    :return: gamma矩阵\n",
        "    \"\"\"\n",
        "    # 1. 获取相关变量\n",
        "    T, n = np.shape(alpha)\n",
        "\n",
        "    # 2. 遍历更新\n",
        "    for t in range(T):\n",
        "        # 2.1. 累加alpha和beta值(ppt上分子部分)\n",
        "        for i in range(n):\n",
        "            gamma[t][i] = alpha[t][i] + beta[t][i]\n",
        "\n",
        "        # 2.2. 计算log_sum_exp的值（ppt上分母部分）\n",
        "        lse = log_sum_exp(gamma[t])\n",
        "\n",
        "        # 2.3. 计算最终结果\n",
        "        for i in range(n):\n",
        "            gamma[t][i] -= lse\n",
        "\n",
        "    # 3. 返回最终结果\n",
        "    return gamma\n",
        "\n",
        "\n",
        "def calc_ksi(alpha, beta, A, B, Q, ksi, fetch_index_by_obs_seq=None):\n",
        "    \"\"\"\n",
        "    计算时刻t的时候状态为i，时刻t+1的时候状态为j的联合概率ksi\n",
        "    :param alpha:  传入的alpha矩阵 => 经过log转换后的\n",
        "    :param beta:  传入的beta矩阵 => 经过log转换后的\n",
        "    :param A: 状态转移矩阵, n*n => 经过对数转换\n",
        "    :param B:  状态和观测值之间的转移矩阵, n*m => 经过对数转换\n",
        "    :param Q:  观测值序列, 长度为T\n",
        "    :param ksi: 待求解的ksi概率矩阵，最终结果是需要经过log转换的\n",
        "    :param fetch_index_by_obs_seq: 根据序列获取对应的索引值，可以为None；是一个接受两个参数的函数，第一个参数为序列，第二个参数为索引值\n",
        "    :return: 返回ksi矩阵\n",
        "    \"\"\"\n",
        "    # 1. 初始化\n",
        "    # 初始化序列转换为索引的方法\n",
        "    fetch_index_by_obs_seq_f = fetch_index_by_obs_seq\n",
        "    if fetch_index_by_obs_seq_f is None:\n",
        "        fetch_index_by_obs_seq_f = lambda obs, obs_index: ord(obs[obs_index])\n",
        "\n",
        "    # 2. 变量获取\n",
        "    T, n = np.shape(alpha)\n",
        "\n",
        "    # 3. 开始迭代更新ksi矩阵\n",
        "    tmp = np.zeros((n, n))\n",
        "    for t in range(T - 1):\n",
        "        # 3.1 计算t时刻状态为i，t+1时刻状态为j的概率值（ppt上的分子部分）\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                tmp[i][j] = alpha[t][i] + A[i][j] + beta[t + 1][j] + B[j][fetch_index_by_obs_seq_f(Q, t + 1)]\n",
        "\n",
        "        # 3.2 计算log_sum_exp的值(ppt上分母部分)\n",
        "        lse = log_sum_exp(tmp.flat)\n",
        "\n",
        "        # 3.3 计算最终的结果值\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                ksi[t][i][j] = tmp[i][j] - lse\n",
        "\n",
        "    # 4. 返回最终结果\n",
        "    ksi\n",
        "\n",
        "\n",
        "def baum_welch(pi, A, B, Q, max_iter=10, fetch_index_by_obs_seq=None):\n",
        "    \"\"\"\n",
        "    根据传入的初始概率矩阵(pi、A、B)以及观测序列Q，使用baum_welch算法进行迭代求解最终的pi、A、B的值；最大迭代次数默认为10；最终更新结果保存在传入的参数矩阵中(pi\\A\\B)\n",
        "    :param pi: 初始的状态随机概率矩阵, n*1 => 经过对数转换\n",
        "    :param A:  状态转移矩阵, n*n => 经过对数转换\n",
        "    :param B:  状态和观测值之间的转移矩阵, n*m => 经过对数转换\n",
        "    :param Q:  观测值序列, 长度为T\n",
        "    :param max_iter: 最大迭代次数，默认为10\n",
        "    :param fetch_index_by_obs_seq: 根据序列获取对应的索引值，可以为None；是一个接受两个参数的函数，第一个参数为序列，第二个参数为索引值\n",
        "    :return:  返回(pi, A, B)\n",
        "    \"\"\"\n",
        "    # 1. 初始化\n",
        "    fetch_index_by_obs_seq_f = fetch_index_by_obs_seq\n",
        "    if fetch_index_by_obs_seq_f is None:\n",
        "        # 默认是使用ord函数将对应位置的字符转换为ASCII码，eg: ord('a')=97; ord('中')=20013\n",
        "        fetch_index_by_obs_seq_f = lambda obs, obs_index: ord(obs[obs_index])\n",
        "\n",
        "    # 2. 初始化相关参数\n",
        "    T = len(Q)\n",
        "    n = np.shape(A)[0]\n",
        "    if len(np.shape(B)) == 1:\n",
        "        m = 1\n",
        "    else:\n",
        "        m = np.shape(B)[1]\n",
        "    alpha_ = np.zeros((T, n))\n",
        "    beta_ = np.zeros((T, n))\n",
        "    gamma_ = np.zeros((T, n))\n",
        "    ksi_ = np.zeros((T - 1, n, n))\n",
        "\n",
        "    # 3. 开始遍历求解\n",
        "    for time in range(max_iter):\n",
        "        # 3.1 分别计算在当前情况下的alphe、beta、gamma、ksi的值\n",
        "        calc_alpha(pi, A, B, Q, alpha_, fetch_index_by_obs_seq_f)\n",
        "        calc_beta(pi, A, B, Q, beta_, fetch_index_by_obs_seq_f)\n",
        "        calc_gamma(alpha_, beta_, gamma_)\n",
        "        calc_ksi(alpha_, beta_, A, B, Q, ksi_, fetch_index_by_obs_seq_f)\n",
        "\n",
        "        # 3.2 更新pi的值\n",
        "        for i in range(n):\n",
        "            pi[i] = gamma_[0][i]\n",
        "\n",
        "        # 3.3 更新A的值\n",
        "        tmp1 = np.zeros(T - 1)  # 对应ppt上分子\n",
        "        tmp2 = np.zeros(T - 1)  # 对应ppt上的分母\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                # 3.3.1 获取所有时刻从状态i转移到状态j的概率值\n",
        "                for t in range(T - 1):\n",
        "                    tmp1[t] = ksi_[t][i][j]\n",
        "                    tmp2[t] = gamma_[t][i]\n",
        "\n",
        "                # 3.3.2 计算状态转移矩阵\n",
        "                A[i][j] = log_sum_exp(tmp1) - log_sum_exp(tmp2)\n",
        "\n",
        "        # 3.4 更新B的值\n",
        "        tmp1 = np.zeros(T)  # 对应ppt上分子\n",
        "        tmp2 = np.zeros(T)  # 对应ppt上的分母\n",
        "        for i in range(n):\n",
        "            for o in range(m):\n",
        "                # 3.4.1 获取所有时刻位于状态i的概率\n",
        "                valid = 0\n",
        "                for t in range(T):\n",
        "                    # a. 计算分子的值\n",
        "                    if o == fetch_index_by_obs_seq_f(Q, t):\n",
        "                        # 当前观测值和对应观测值一致，计算分子\n",
        "                        tmp1[valid] = gamma_[t][i]\n",
        "                        valid += 1\n",
        "                    # b. 累积分母的值\n",
        "                    tmp2[t] = gamma_[t][i]\n",
        "\n",
        "                # 3.4.2 更新状态转移矩阵的值B\n",
        "                if valid == 0:\n",
        "                    # 表示没有从i和o的观测值转移矩阵\n",
        "                    B[i][o] = 0\n",
        "                else:\n",
        "                    B[i][o] = log_sum_exp(tmp1[:valid]) - log_sum_exp(tmp2)\n",
        "\n",
        "    # 4. 返回最终结果\n",
        "    return (pi, A, B)\n",
        "\n",
        "\n",
        "def viterbi(pi, A, B, Q, fetch_index_by_obs_seq=None):\n",
        "    \"\"\"\n",
        "    计算观测序列\n",
        "    :param pi: 初始的状态随机概率矩阵, n*1 => 经过对数转换\n",
        "    :param A:  状态转移矩阵, n*n => 经过对数转换\n",
        "    :param B:  状态和观测值之间的转移矩阵, n*m => 经过对数转换\n",
        "    :param Q:  观测值序列, 长度为T\n",
        "    :param fetch_index_by_obs_seq: 根据序列获取对应的索引值，可以为None；是一个接受两个参数的函数，第一个参数为序列，第二个参数为索引值\n",
        "    :return: 返回decode序列\n",
        "    \"\"\"\n",
        "    # 1.初始化\n",
        "    # 初始化序列转换为索引的方法\n",
        "    fetch_index_by_obs_seq_f = fetch_index_by_obs_seq\n",
        "    if fetch_index_by_obs_seq_f is None:\n",
        "        fetch_index_by_obs_seq_f = lambda obs, obs_index: ord(obs[obs_index])\n",
        "\n",
        "    # 2. 相关参数初始化\n",
        "    T = len(Q)\n",
        "    n = np.shape(A)[0]\n",
        "    delta = np.zeros((T, n))\n",
        "    # 存储的是上一个最优状态值,eg: pre_optima_index[t][i]表示时刻t对应状态为i，此时上一个时刻的最优状态（delta最大）为pre_optima_index[t][i]\n",
        "    pre_optima_index = np.zeros((T, n), dtype=np.int)\n",
        "\n",
        "    # 3 计算t=1时刻的delta值\n",
        "    for i in range(n):\n",
        "        delta[0][i] = pi[i] + B[i][fetch_index_by_obs_seq_f(Q, 0)]\n",
        "\n",
        "    # 4 计算t=2、3、4.....时刻的delta值\n",
        "    for t in range(1, T):\n",
        "        for i in range(n):\n",
        "            # 4.1 获取最大的值以及对应的最优索引位置\n",
        "            max_delta = delta[t - 1][0] + A[0][i]\n",
        "            optima_index = 0\n",
        "            for j in range(1, n):\n",
        "                tmp_delta = delta[t - 1][j] + A[j][i]\n",
        "                if max_delta < tmp_delta:\n",
        "                    max_delta = tmp_delta\n",
        "                    optima_index = j\n",
        "\n",
        "            # 4.2 计算最终的delta值以及最优索引位置\n",
        "            delta[t][i] = max_delta + B[i][fetch_index_by_obs_seq_f(Q, t)]\n",
        "            pre_optima_index[t][i] = optima_index\n",
        "\n",
        "    # 5. 解码操作，查找到最大的结果值（回溯找最大的路径）\n",
        "    decode = [-1 for i in range(T)]\n",
        "    # 先找最后一个时刻的delta最大值\n",
        "    max_delta_index = 0\n",
        "    for i in range(1, n):\n",
        "        if delta[T - 1][i] > delta[T - 1][max_delta_index]:\n",
        "            max_delta_index = i\n",
        "    decode[T - 1] = max_delta_index\n",
        "    # 再根据转移的路径(最大转移路径), 找出最终的链路\n",
        "    for t in range(T - 2, -1, -1):\n",
        "        max_delta_index = pre_optima_index[t + 1][max_delta_index]\n",
        "        decode[t] = max_delta_index\n",
        "\n",
        "    # 6. 返回最终结果\n",
        "    return decode"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYlp_61d14Fm",
        "outputId": "a25488a1-4195-4779-e93b-38c250604180",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "pi = np.array([0.2, 0.5, 0.3])\n",
        "A = np.array([\n",
        "    [0.5, 0.4, 0.1],\n",
        "    [0.2, 0.2, 0.6],\n",
        "    [0.2, 0.5, 0.3]\n",
        "])\n",
        "B = np.array([\n",
        "    [0.4, 0.6],\n",
        "    [0.8, 0.2],\n",
        "    [0.5, 0.5]\n",
        "])\n",
        "# 对A\\B\\pi进行log转换、\n",
        "pi = np.log(pi)\n",
        "A = np.log(A)\n",
        "B = np.log(B)\n",
        "\n",
        "Q = ['白', '黑', '白', '白', '黑']\n",
        "T = len(Q)\n",
        "n = len(A)\n",
        "\n",
        "print(\"测试前向概率计算....................\")\n",
        "alpha = np.zeros((T, n))\n",
        "# 开始计算\n",
        "calc_alpha(pi, A, B, Q, alpha, convert_obs_seq_2_index)\n",
        "# 输出最终结果\n",
        "# print(np.exp(alpha))\n",
        "print(alpha)\n",
        "\n",
        "# 计算最终概率值：\n",
        "p = log_sum_exp(alpha[T - 1].flat)\n",
        "print(Q, end=\"->出现的概率为:\")\n",
        "print(np.exp(p))\n",
        "\n",
        "print(\"测试后向概率计算....................\")\n",
        "beta = np.zeros((T, n))\n",
        "# 开始计算\n",
        "calc_beta(pi, A, B, Q, beta, convert_obs_seq_2_index)\n",
        "# 输出最终结果\n",
        "# print(np.exp(beta))\n",
        "print(beta)\n",
        "\n",
        "# 计算最终概率值：\n",
        "tmp_p = np.zeros(n)\n",
        "for i in range(n):\n",
        "    tmp_p[i] = pi[i] + B[i][convert_obs_seq_2_index(Q, 0)] + beta[0][i]\n",
        "print(\"--------------\")\n",
        "p = log_sum_exp(tmp_p)\n",
        "print(Q, end=\"->出现的概率为:\")\n",
        "print(np.exp(p))\n",
        "\n",
        "print(\"测试gamma矩阵应用在最大概率预测的情况下.....................\")\n",
        "gamma = np.zeros((T, n))\n",
        "calc_gamma(alpha, beta, gamma)\n",
        "# print(np.exp(gamma))\n",
        "print(gamma)\n",
        "print(\"各个时刻最大概率的盒子为:\", end='')\n",
        "index = ['盒子1', '盒子2', '盒子3']\n",
        "for p in gamma:\n",
        "    print(index[p.tolist().index(np.max(p))], end=\"\\t\")\n",
        "print()\n",
        "\n",
        "print(\"测试ksi矩阵....................\")\n",
        "ksi = np.zeros((T - 1, n, n))\n",
        "calc_ksi(alpha, beta, A, B, Q, ksi,convert_obs_seq_2_index)\n",
        "print(ksi)\n",
        "\n",
        "print(\"baum welch算法应用.......................\")\n",
        "baum_welch(pi, A, B, Q, max_iter=3, fetch_index_by_obs_seq=convert_obs_seq_2_index)\n",
        "print(\"最终的pi矩阵：\", end='')\n",
        "print(np.exp(pi))\n",
        "print(\"最终的状态转移矩阵：\")\n",
        "print(np.exp(A))\n",
        "print(\"最终的状态-观测值转移矩阵：\")\n",
        "print(np.exp(B))\n",
        "\n",
        "print(\"viterbi算法应用.....................\")\n",
        "state_seq = viterbi(pi, A, B, Q, convert_obs_seq_2_index)\n",
        "print(\"最终结果为:\", end='')\n",
        "print(state_seq)\n",
        "state = ['盒子1', '盒子2', '盒子3']\n",
        "for i in state_seq:\n",
        "    print(state[i], end='\\t')\n",
        "\n",
        "print(\"\\n根据当前的状态值，预测未来的状态值....................\")\n",
        "### 假定当前状态为: 盒子1，那么接下来4次的状态分别是多少\n",
        "### 假定当前状态为: 盒子1, 盒子2，那么接下来3次的状态分别是多少\n",
        "### 假定当前状态为: 盒子1, 盒子3，那么接下来3次的状态分别是多少\n",
        "### 假定当前状态为: 盒子1, 盒子1，那么接下来3次的状态分别是多少\n",
        "current_state = [0, 0]\n",
        "for t in range(1, 4):\n",
        "    current_i = current_state[-1]\n",
        "    max_ksi_j = ksi[t][current_i][0]\n",
        "    max_j = 0\n",
        "    for j in range(1, n):\n",
        "        tmp = ksi[t][current_i][j]\n",
        "        if tmp > max_ksi_j:\n",
        "            max_ksi_j = tmp\n",
        "            max_j = j\n",
        "\n",
        "    current_state.append(max_j)\n",
        "print(current_state)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "测试前向概率计算....................\n",
            "[[-2.52572864 -0.91629073 -1.89711998]\n",
            " [-2.40794561 -3.28608457 -1.92072985]\n",
            " [-3.4200133  -2.37103525 -3.27822782]\n",
            " [-4.07285395 -3.20676743 -3.34372927]\n",
            " [-4.25425309 -5.03406353 -4.00121617]]\n",
            "['白', '黑', '白', '白', '黑']->出现的概率为:0.03900936690000001\n",
            "测试后向概率计算....................\n",
            "[[-2.83594215 -2.71456226 -2.95360138]\n",
            " [-2.00905764 -1.98525199 -1.90501104]\n",
            " [-1.37951738 -1.51868355 -1.2949922 ]\n",
            " [-0.84397007 -0.77652879 -0.99425227]\n",
            " [ 0.          0.          0.        ]]\n",
            "--------------\n",
            "['白', '黑', '白', '白', '黑']->出现的概率为:0.03900936690000001\n",
            "测试gamma矩阵应用在最大概率预测的情况下.....................\n",
            "[[-2.11771731 -0.38689951 -1.60676788]\n",
            " [-1.17304976 -2.02738308 -0.5817874 ]\n",
            " [-1.55557719 -0.64576532 -1.32926654]\n",
            " [-1.67287053 -0.73934273 -1.09402805]\n",
            " [-1.01029961 -1.79011005 -0.75726269]]\n",
            "各个时刻最大概率的盒子为:盒子2\t盒子3\t盒子2\t盒子2\t盒子3\t\n",
            "测试ksi矩阵....................\n",
            "[[[-2.4948056  -3.79275579 -4.18251847]\n",
            "  [-1.80165842 -2.87646506 -0.78132109]\n",
            "  [-2.78248767 -2.94100358 -2.45529752]]\n",
            "\n",
            " [[-2.15294741 -1.82210996 -3.4547166 ]\n",
            "  [-3.94737711 -3.3933961  -2.5410961 ]\n",
            "  [-2.58202239 -1.11175065 -1.86888855]]\n",
            "\n",
            " [[-2.62946779 -2.09202288 -4.16604436]\n",
            "  [-2.49678048 -1.73619202 -1.32530685]\n",
            "  [-3.40397305 -1.72709386 -2.92564659]]\n",
            "\n",
            " [[-2.03287327 -3.35462911 -3.82463274]\n",
            "  [-2.08307748 -3.18168977 -1.16678675]\n",
            "  [-2.22003932 -2.40236087 -1.99689577]]]\n",
            "baum welch算法应用.......................\n",
            "最终的pi矩阵：[0.02133259 0.95211043 0.02655698]\n",
            "最终的状态转移矩阵：\n",
            "[[0.45155968 0.45559751 0.09284281]\n",
            " [0.22185841 0.11289179 0.6652498 ]\n",
            " [0.20583914 0.48940482 0.30475603]]\n",
            "最终的状态-观测值转移矩阵：\n",
            "[[0.43630972 0.56369028]\n",
            " [0.95945807 0.04054193]\n",
            " [0.2797217  0.7202783 ]]\n",
            "viterbi算法应用.....................\n",
            "最终结果为:[1, 2, 1, 1, 2]\n",
            "盒子2\t盒子3\t盒子2\t盒子2\t盒子3\t\n",
            "根据当前的状态值，预测未来的状态值....................\n",
            "[0, 0, 1, 2, 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-QAdvvt4evF"
      },
      "source": [
        "\"\"\"训练分词用的HMM\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "\n",
        "\n",
        "random.seed(28)\n",
        "infinite = float(-2 ** 31)\n",
        "\n",
        "\n",
        "def log_normalize(a):\n",
        "    s = 0\n",
        "    for i in a:\n",
        "        s += i\n",
        "    s = math.log(s)\n",
        "    for i in range(len(a)):\n",
        "        if a[i] == 0:\n",
        "            a[i] = infinite\n",
        "        else:\n",
        "            a[i] = math.log(a[i]) - s\n",
        "\n",
        "\n",
        "def fit(train_file_path, mode='r', encoding='utf-8'):\n",
        "    \"\"\"\n",
        "    进行模型训练，并返回pi、A、B\n",
        "    :param train_file_path:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # 1. 加载数据\n",
        "    with open(train_file_path, mode=mode, encoding=encoding) as reader:\n",
        "        # 读取所有数据（因为数据格式第一个字符是不可见字符<文件描述符>）\n",
        "        sentence = reader.read()[1:]\n",
        "\n",
        "    # 1. 初始化pi、A、B\n",
        "    pi = np.zeros(4)\n",
        "    A = np.zeros((4, 4))\n",
        "    B = np.zeros((4, 65536))\n",
        "\n",
        "    # 2. 模型训练（使用MLE来预测） 0B/1M/2E/3S\n",
        "    tokens = sentence.split(' ')\n",
        "    last_i = 2  # 上一个词结束的状态\n",
        "    for k, token in enumerate(tokens):\n",
        "        token = token.strip()\n",
        "        n = len(token)\n",
        "        if n <= 0:\n",
        "            continue\n",
        "\n",
        "        if n == 1:\n",
        "            pi[3] += 1\n",
        "            A[last_i][3] += 1\n",
        "            B[3][ord(token[0])] += 1\n",
        "            last_i = 3\n",
        "            continue\n",
        "\n",
        "        # 初始化向量\n",
        "        pi[0] += 1  # 作为开始\n",
        "        pi[2] += 1  # 作为结束\n",
        "        pi[1] += (n - 2)  # 中间词数目\n",
        "\n",
        "        # 转移矩阵\n",
        "        A[last_i][0] += 1\n",
        "        last_i = 2\n",
        "        if n == 2:\n",
        "            A[0][2] += 1\n",
        "        else:\n",
        "            A[0][1] += 1\n",
        "            A[1][1] += (n - 3)\n",
        "            A[1][2] += 1\n",
        "\n",
        "        # 发射矩阵\n",
        "        B[0][ord(token[0])] += 1\n",
        "        B[2][ord(token[n - 1])] += 1\n",
        "        for i in range(1, n - 1):\n",
        "            B[1][ord(token[i])] += 1\n",
        "\n",
        "    # 正则化\n",
        "    log_normalize(pi)\n",
        "    for i in range(4):\n",
        "        log_normalize(A[i])\n",
        "        log_normalize(B[i])\n",
        "\n",
        "    # 结果返回\n",
        "    return pi, A, B\n",
        "\n",
        "\n",
        "def dump(pi, A, B):\n",
        "    \"\"\"\n",
        "    模型保存\n",
        "    :param pi:\n",
        "    :param A:\n",
        "    :param B:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    n, m = np.shape(B)\n",
        "\n",
        "    # 1. pi输出\n",
        "    with open(\"pi.txt\", \"w\") as f_pi:\n",
        "        f_pi.write(str(n))\n",
        "        f_pi.write('\\n')\n",
        "        f_pi.write(' '.join(map(str, pi)))\n",
        "\n",
        "    # 2. A输出\n",
        "    with open('A.txt', 'w') as f_a:\n",
        "        f_a.write(str(n))\n",
        "        f_a.write('\\n')\n",
        "        for a in A:\n",
        "            f_a.write(' '.join(map(str, a)))\n",
        "            f_a.write('\\n')\n",
        "\n",
        "    # 3. B输出\n",
        "    with open('B.txt', 'w') as f_b:\n",
        "        f_b.write(str(n))\n",
        "        f_b.write('\\n')\n",
        "        f_b.write(str(m))\n",
        "        f_b.write('\\n')\n",
        "        for b in B:\n",
        "            f_b.write(' '.join(map(str, b)))\n",
        "            f_b.write('\\n')\n",
        "\n",
        "\n",
        "def load():\n",
        "    \"\"\"\n",
        "    模型加载\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    with open('pi.txt', 'r', encoding='utf-8') as f_pi:\n",
        "        f_pi.readline()  # 第一行不需要\n",
        "        line = f_pi.readline()\n",
        "        pi = list(map(float, line.strip().split(' ')))\n",
        "\n",
        "    with open('A.txt', 'r', encoding='utf-8') as f_a:\n",
        "        n = int(f_a.readline())\n",
        "        A = np.zeros((n, n))\n",
        "        i = 0\n",
        "        for line in f_a:\n",
        "            j = 0\n",
        "            for v in map(float, line.strip().split(' ')):\n",
        "                A[i][j] = v\n",
        "                j += 1\n",
        "            i += 1\n",
        "\n",
        "    with open('B.txt', 'r', encoding='utf-8') as f_b:\n",
        "        n = int(f_b.readline())\n",
        "        m = int(f_b.readline())\n",
        "        B = np.zeros((n, m))\n",
        "        i = 0\n",
        "        for line in f_b:\n",
        "            j = 0\n",
        "            for v in map(float, line.strip().split(' ')):\n",
        "                B[i][j] = v\n",
        "                j += 1\n",
        "            i += 1\n",
        "\n",
        "    return pi, A, B\n",
        "\n",
        "\n",
        "def segment(sentence, decode):\n",
        "    \"\"\"\n",
        "    分词\n",
        "    :param sentence:\n",
        "    :param decode:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    T = len(sentence)\n",
        "    i = 0\n",
        "    while i < T:  # B/M/E/S\n",
        "        if decode[i] == 0 or decode[i] == 1:  # Begin\n",
        "            j = i + 1\n",
        "            while j < T:\n",
        "                if decode[j] == 2:\n",
        "                    break\n",
        "                j += 1\n",
        "            print(sentence[i:j + 1], end=' | ')\n",
        "        elif decode[i] == 3 or decode[i] == 2:  # single\n",
        "            print(sentence[i:i + 1], end=' | ')\n",
        "        else:\n",
        "            print(\"Error\")\n",
        "        i += 1\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLeiH0gI5nb2",
        "outputId": "90f520dd-54fe-4e40-e949-8bdbca661d43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 1. 模型训练\n",
        "# 该数据默认是四个状态\"B/M/E/S\"\n",
        "# B:begin, M:middle, E:end, S:single\n",
        "# 分别代表每个状态代表的是该字在词语中的位置，B代表该字是词语中的起始字，M代表是词语中的中间字，E代表是词语中的结束字，S则代表是单字成词。\n",
        "pi, A, B = fit('pku_training.utf8')\n",
        "print(pi)\n",
        "print(A)\n",
        "print(B)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.13813028 -2.63283402 -1.13813028 -1.24726168]\n",
            "[[-2.14748365e+09 -1.91884919e+00 -1.58732900e-01 -2.14748365e+09]\n",
            " [-2.14748365e+09 -1.06226695e+00 -4.24145455e-01 -2.14748365e+09]\n",
            " [-7.20476004e-01 -2.14748365e+09 -2.14748365e+09 -6.66545397e-01]\n",
            " [-5.57413705e-01 -2.14748365e+09 -2.14748365e+09 -8.50241534e-01]]\n",
            "[[-2.14748365e+09 -2.14748365e+09 -2.14748365e+09 ... -2.14748365e+09\n",
            "  -2.14748365e+09 -2.14748365e+09]\n",
            " [-2.14748365e+09 -2.14748365e+09 -2.14748365e+09 ... -2.14748365e+09\n",
            "  -2.14748365e+09 -2.14748365e+09]\n",
            " [-2.14748365e+09 -2.14748365e+09 -2.14748365e+09 ... -2.14748365e+09\n",
            "  -2.14748365e+09 -2.14748365e+09]\n",
            " [-2.14748365e+09 -2.14748365e+09 -2.14748365e+09 ... -2.14748365e+09\n",
            "  -2.14748365e+09 -2.14748365e+09]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tP-88mC6Bgw"
      },
      "source": [
        "# 2. 模型输出\n",
        "dump(pi, A, B)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQdnPywz5Vml",
        "outputId": "e8ecbcb8-e896-4a3b-cb60-c57655bdedef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# # 2. 模型输出\n",
        "# dump(pi, A, B)\n",
        "\n",
        "# 3. 模型加载\n",
        "pi, A, B = load()\n",
        "print(pi)\n",
        "print(A)\n",
        "print(B)\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-1.1381302786652014, -2.632834016555254, -1.1381302786652014, -1.247261683317193]\n",
            "[[-2.14748365e+09 -1.91884919e+00 -1.58732900e-01 -2.14748365e+09]\n",
            " [-2.14748365e+09 -1.06226695e+00 -4.24145455e-01 -2.14748365e+09]\n",
            " [-7.20476004e-01 -2.14748365e+09 -2.14748365e+09 -6.66545397e-01]\n",
            " [-5.57413705e-01 -2.14748365e+09 -2.14748365e+09 -8.50241534e-01]]\n",
            "[[-2.14748365e+09 -2.14748365e+09 -2.14748365e+09 ... -2.14748365e+09\n",
            "  -2.14748365e+09 -2.14748365e+09]\n",
            " [-2.14748365e+09 -2.14748365e+09 -2.14748365e+09 ... -2.14748365e+09\n",
            "  -2.14748365e+09 -2.14748365e+09]\n",
            " [-2.14748365e+09 -2.14748365e+09 -2.14748365e+09 ... -2.14748365e+09\n",
            "  -2.14748365e+09 -2.14748365e+09]\n",
            " [-2.14748365e+09 -2.14748365e+09 -2.14748365e+09 ... -2.14748365e+09\n",
            "  -2.14748365e+09 -2.14748365e+09]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpmWqSp76toH",
        "outputId": "c715ecf6-2b31-4c67-d52a-1e1689b31219",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 4. 进行分词操作\n",
        "with open('novel.txt', 'r', encoding='utf-8') as reader:\n",
        "    data = reader.read()[1:]\n",
        "decode = viterbi(pi, A, B, data)\n",
        "segment(data, decode)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "美 | 关系 | 系 | 持续 | 续 | 交恶 | 恶 | 的 | 大 | 背景 | 景 | 下 | ， | 外界 | 界 | 的 | 目光 | 光 | 都 | 聚焦 | 焦 | 在 | 中国 | 国 | 如何 | 何 | 保持 | 持 | 发展 | 展 | ， | 尤其 | 其 | 是 | 近年 | 年 | 来 | 被 | 反复 | 复 | 提及的2035年 | 及的2035年 | 的2035年 | 2035年 | 035年 | 35年 | 5年 | 年 | 远景 | 景 | 目标 | 标 | ， | 届 | 时 | 中国 | 国 | 经济 | 济 | 是 | 否会 | 会 | 全面 | 面 | 超越 | 越 | 美国 | 国 | ？ | 以及 | 及 | 为 | 了 | 达到 | 到 | 这 | 一 | 目标 | 标 | ， | 中国 | 国 | 面临 | 临 | 哪些 | 些 | 困难 | 难 | 和 | 挑战 | 战 | ？ | "
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}