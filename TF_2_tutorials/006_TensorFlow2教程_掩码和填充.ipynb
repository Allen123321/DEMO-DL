{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "006.TensorFlow2教程-掩码和填充.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPS5+ICTBNME9QNgNnb1p0L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Allen123321/DEMO-DL/blob/master/006_TensorFlow2%E6%95%99%E7%A8%8B_%E6%8E%A9%E7%A0%81%E5%92%8C%E5%A1%AB%E5%85%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5y4jTEk0_4e"
      },
      "source": [
        "在构建深度学习模型，特别是进行序列的相关任务时，经常会用到掩码和填充技术"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_8S0HZOz_hA"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESi8nVd91Et3"
      },
      "source": [
        "## 1 填充序列数据\r\n",
        "处理序列数据时，常常会遇到不同长度的文本，例如处理某些句子时："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "porTSRy-1LQK",
        "outputId": "1f7c91e6-74e1-43bb-91bb-c7a38ff1bef9"
      },
      "source": [
        "[\r\n",
        "  [\"The\", \"weather\", \"will\", \"be\", \"nice\", \"tomorrow\"],\r\n",
        "  [\"How\", \"are\", \"you\", \"doing\", \"today\"],\r\n",
        "  [\"Hello\", \"world\", \"!\"]\r\n",
        "]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The', 'weather', 'will', 'be', 'nice', 'tomorrow'],\n",
              " ['How', 'are', 'you', 'doing', 'today'],\n",
              " ['Hello', 'world', '!']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT5J03Ut1Ps6",
        "outputId": "dbf83429-52d7-4e59-ebf3-870dd22f3a47"
      },
      "source": [
        "#计算机无法理解字符，我们一般将词语转换为对应的id\r\n",
        "[\r\n",
        "  [83, 91, 1, 645, 1253, 927],\r\n",
        "  [73, 8, 3215, 55, 927],\r\n",
        "  [71, 1331, 4231]\r\n",
        "]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[83, 91, 1, 645, 1253, 927], [73, 8, 3215, 55, 927], [71, 1331, 4231]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm6OIDvv1cOd"
      },
      "source": [
        "由于深度信息模型的输入一般是固定的张量，所以我们需要对短文本进行填充（或对长文本进行截断），使每个样本的长度相同。 Keras提供了一个API，可以通过填充和截断，获取等长的数据： tf.keras.preprocessing.sequence.pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neqiWFWh1gvP",
        "outputId": "69488a06-c5ce-4eb7-e88e-d69650126e71"
      },
      "source": [
        "raw_inputs = [\r\n",
        "  [83, 91, 1, 645, 1253, 927],\r\n",
        "  [73, 8, 3215, 55, 927],\r\n",
        "  [711, 632, 71]\r\n",
        "]\r\n",
        "# 默认左填充\r\n",
        "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs)\r\n",
        "print(padded_inputs)\r\n",
        "# 右填充需要设 padding='post'\r\n",
        "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\r\n",
        "                                                             padding='post')\r\n",
        "print(\"**************************\"*2)\r\n",
        "print(padded_inputs)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  83   91    1  645 1253  927]\n",
            " [   0   73    8 3215   55  927]\n",
            " [   0    0    0  711  632   71]]\n",
            "****************************************************\n",
            "[[  83   91    1  645 1253  927]\n",
            " [  73    8 3215   55  927    0]\n",
            " [ 711  632   71    0    0    0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkHrv56g2g4D"
      },
      "source": [
        "## 2 掩码\r\n",
        "现在所有样本都获得了同样的长度，在求损失函数或输出的时候往往需要知道那些部分是填充的，需要忽略。这种忽略机制就是掩码。\r\n",
        "\r\n",
        "keras中三种添加掩码的方法：\r\n",
        "\r\n",
        "+ 添加一个keras.layer.Masking的网络层\r\n",
        "+ 配置keras.layers.Embedding层的mask_zero=True\r\n",
        "+ 在支持mark的网络层中，手动传递参数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKY1Lmhj_LpM"
      },
      "source": [
        "## 2.1 掩码生成层：Embedding和Masking\r\n",
        "Embedding和Masking会创建一个掩码张量，附加到返回的输出中。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RFiA00P_Rza",
        "outputId": "e1d3a66d-57e1-457e-a90f-19506c1ce65e"
      },
      "source": [
        "embedding = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\r\n",
        "mask_output= embedding(padded_inputs)\r\n",
        "print(mask_output._keras_mask)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ True  True  True  True  True  True]\n",
            " [ True  True  True  True  True False]\n",
            " [ True  True  True False False False]], shape=(3, 6), dtype=bool)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdH_bZe3AlSY",
        "outputId": "1f89304d-d3ef-4c46-a1cb-62f9c62e1720"
      },
      "source": [
        "# 使用掩码层\r\n",
        "masking_layer = layers.Masking()\r\n",
        "unmasked_embedding = tf.cast(\r\n",
        "tf.tile(tf.expand_dims(padded_inputs, axis=-1), [1, 1, 16]),\r\n",
        "tf.float32)\r\n",
        "masked_embedding = masking_layer(unmasked_embedding)\r\n",
        "print(masked_embedding._keras_mask)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ True  True  True  True  True  True]\n",
            " [ True  True  True  True  True False]\n",
            " [ True  True  True False False False]], shape=(3, 6), dtype=bool)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TsngjdbAwC3"
      },
      "source": [
        "mark是带有2D布尔张量(batch_size, sequence_length)，其中每个单独的False指示在处理过程中应忽略相应的时间步数据。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoDlMYXKAyIK"
      },
      "source": [
        "## 2.2 函数API和序列API中使用掩码\r\n",
        "使用函数式API或序列API时，由Embedding或Masking层生成的掩码将通过网络传播到能够使用它们的任何层（例如RNN层）。Keras将自动获取与输入相对应的掩码，并将其传递给知道如何使用该掩码的任何层。<br>\r\n",
        "请注意，在子类化模型或图层的call方法中，掩码不会自动传播，因此将需要手动将mask参数传递给需要的图层。\r\n",
        "\r\n",
        "下面展示了LSTM层怎么自动接受掩码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf6lAZBaBcx0"
      },
      "source": [
        "# 序列式API\r\n",
        "model = tf.keras.Sequential([\r\n",
        "  layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True),\r\n",
        "  layers.LSTM(32),\r\n",
        "])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXzNgyq1Bh3k"
      },
      "source": [
        "\r\n",
        "# 函数式API\r\n",
        "inputs = tf.keras.Input(shape=(None,), dtype='int32')\r\n",
        "x = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)(inputs)\r\n",
        "outputs = layers.LSTM(32)(x)\r\n",
        "\r\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZzUP6jrBpg3"
      },
      "source": [
        "**也可以直接在层间传递掩码参数** <br>\r\n",
        "\r\n",
        "可以处理掩码的图层（例如LSTM图层）在其图层中的call方法中有一个mask参数。\r\n",
        "\r\n",
        "同时，产生掩码的图层（例如Embedding）会公开compute_mask(input, previous_mask)，以获取掩码。\r\n",
        "\r\n",
        "因此，可以执行以下操作："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B99Lj06Bz0P",
        "outputId": "4bfe9f45-bc11-45e0-e296-1de15694a85f"
      },
      "source": [
        "class MyLayer(layers.Layer):\r\n",
        "  \r\n",
        "    def __init__(self, **kwargs):\r\n",
        "        super(MyLayer, self).__init__(**kwargs)\r\n",
        "        self.embedding = layers.Embedding(input_dim=5000, output_dim=16, mask_zero=True)\r\n",
        "        self.lstm = layers.LSTM(32)\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        x = self.embedding(inputs)\r\n",
        "        # 也可手动构造掩码\r\n",
        "        mask = self.embedding.compute_mask(inputs)\r\n",
        "        output = self.lstm(x, mask=mask)  # The layer will ignore the masked values\r\n",
        "        return output\r\n",
        "\r\n",
        "layer = MyLayer()\r\n",
        "x = np.random.random((32, 10)) * 100\r\n",
        "x = x.astype('int32')\r\n",
        "layer(x)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(32, 32), dtype=float32, numpy=\n",
              "array([[-2.0847986e-04, -3.8266173e-03, -3.6995453e-03, ...,\n",
              "        -3.4576918e-03, -6.8291915e-03,  1.8525604e-03],\n",
              "       [ 5.6297807e-03, -3.2602279e-03,  4.8619909e-03, ...,\n",
              "        -4.4993041e-03,  1.8968499e-03, -3.4376071e-03],\n",
              "       [ 3.9982144e-03,  3.2944002e-03,  9.5590804e-05, ...,\n",
              "        -6.0736854e-04, -2.7561446e-03,  4.0807109e-03],\n",
              "       ...,\n",
              "       [-1.4595116e-02, -3.7352126e-03,  9.5237242e-03, ...,\n",
              "        -1.2509438e-03,  3.1130887e-03,  1.5221540e-02],\n",
              "       [-9.5368549e-03, -9.1638928e-04,  8.1074703e-03, ...,\n",
              "         7.1032969e-03,  6.3297257e-04,  6.9725546e-03],\n",
              "       [-6.5732474e-04, -3.6519307e-03,  1.4861961e-02, ...,\n",
              "        -4.0423088e-03, -3.9191251e-03,  2.9565615e-03]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r8yCiKnCEvt"
      },
      "source": [
        "## 在自定义网络层中支持掩码\r\n",
        "有时，可能需要编写生成掩码的图层（例如Embedding），或需要修改当前掩码的图层。\r\n",
        "\r\n",
        "例如，产生张量的时间维度与其输入不同的任何层，都需要修改当前掩码，以便下游层能够适当考虑掩码的时间步长。\r\n",
        "\r\n",
        "为此，自建网络层应实现layer.compute_mask()方法，该方法将根据输入和当前掩码生成一个新的掩码。\r\n",
        "\r\n",
        "大多数图层都不会修改时间维度，因此无需担心掩盖。compute_mask()在这种情况下，默认行为是仅通过当前蒙版。\r\n",
        "## TemporalSplit修改当前蒙版的图层的示例。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkXWJB63CY2F",
        "outputId": "df66f959-1b83-466f-8953-db0ec49f5f89"
      },
      "source": [
        "\r\n",
        "# 数据拆分时的掩码\r\n",
        "class TemporalSplit(tf.keras.layers.Layer):\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        # 将数据沿时间维度一分为二\r\n",
        "        return tf.split(inputs, 2, axis=1)\r\n",
        "\r\n",
        "    def compute_mask(self, inputs, mask=None):\r\n",
        "        # 将掩码也一分为二\r\n",
        "        if mask is None:\r\n",
        "            return None\r\n",
        "        return tf.split(mask, 2, axis=1)\r\n",
        "\r\n",
        "first_half, second_half = TemporalSplit()(masked_embedding)\r\n",
        "print(first_half._keras_mask)\r\n",
        "print(second_half._keras_mask)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ True  True  True]\n",
            " [ True  True  True]\n",
            " [ True  True  True]], shape=(3, 3), dtype=bool)\n",
            "tf.Tensor(\n",
            "[[ True  True  True]\n",
            " [ True  True False]\n",
            " [False False False]], shape=(3, 3), dtype=bool)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLNkj5IACi_9",
        "outputId": "6fa93f15-c4fa-4596-8a23-5aefc5b31555"
      },
      "source": [
        "class CustomEmbedding(tf.keras.layers.Layer):\r\n",
        "  \r\n",
        "    def __init__(self, input_dim, output_dim, mask_zero=False, **kwargs):\r\n",
        "        super(CustomEmbedding, self).__init__(**kwargs)\r\n",
        "        self.input_dim = input_dim\r\n",
        "        self.output_dim = output_dim\r\n",
        "        self.mask_zero = mask_zero\r\n",
        "\r\n",
        "    def build(self, input_shape):\r\n",
        "        self.embeddings = self.add_weight(\r\n",
        "        shape=(self.input_dim, self.output_dim),\r\n",
        "        initializer='random_normal',\r\n",
        "        dtype='float32')\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        return tf.nn.embedding_lookup(self.embeddings, inputs)\r\n",
        "\r\n",
        "    def compute_mask(self, inputs, mask=None):\r\n",
        "        if not self.mask_zero:\r\n",
        "            return None\r\n",
        "        return tf.not_equal(inputs, 0)\r\n",
        "\r\n",
        "layer = CustomEmbedding(10, 32, mask_zero=True)\r\n",
        "x = np.random.random((3, 10)) * 9\r\n",
        "x = x.astype('int32')\r\n",
        "\r\n",
        "y = layer(x)\r\n",
        "mask = layer.compute_mask(x)\r\n",
        "\r\n",
        "print(mask)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ True  True  True  True  True  True  True  True  True  True]\n",
            " [False  True  True  True  True  True  True  True  True  True]\n",
            " [ True  True False  True False  True  True  True False False]], shape=(3, 10), dtype=bool)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GW-QHzh3Cnph"
      },
      "source": [
        "直接用网络层实现掩码功能：call函数中接受一个mask参数，并用它来确定是否跳过某些时间步。\r\n",
        "\r\n",
        "要编写这样的层，只需在call函数中添加一个mask=None参数即可。只要有可用的输入，与输入关联的掩码将被传递到图层。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goaSCnSXCq59"
      },
      "source": [
        "class MaskConsumer(tf.keras.layers.Layer):\r\n",
        "  \r\n",
        "    def call(self, inputs, mask=None):\r\n",
        "        pass"
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}