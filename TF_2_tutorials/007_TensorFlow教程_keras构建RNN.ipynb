{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "006.TensorFlow教程-keras构建RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOgWWDXeMRuV6A9ElfTp5z+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Allen123321/DEMO-DL/blob/master/006_TensorFlow%E6%95%99%E7%A8%8B_keras%E6%9E%84%E5%BB%BARNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9Jjqxcq-xEg"
      },
      "source": [
        "循环神经网络是一种在时间维度上进行迭代的神经网络，在建模序列数据方面有着优越的性能。 TensorFlow2中包含了主流的rnn网络实现，以Keras RNN API的方式提供调用。其特性如下：\r\n",
        "\r\n",
        "+ 易用性： 内置tf.keras.layers.RNN，tf.keras.layers.LSTM，tf.keras.layers.GRU， 可以快速构建RNN模块。\r\n",
        "+ 易于定制：可以使用自定义操作循环来构建RNN模块，并通过tf.keras.layers.RNN调用。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viGtax1W-nWn",
        "outputId": "f2272417-88bb-401a-ae2d-a12d93e53386"
      },
      "source": [
        "import collections\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "print(tf.__version__)\r\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLtrox4o_xV3"
      },
      "source": [
        "## 1 构建一个简单模型\r\n",
        "keras中内置了三个RNN层\r\n",
        "\r\n",
        "+ tf.keras.layers.SimpleRNN，普通RNN网络。\r\n",
        "+ tf.keras.layers.GRU，门控循环神经网络。\r\n",
        "+ tf.keras.layers.LSTM，长短期记忆神经网络。 下面是一个循环神经网络的例子，它使用LSTM层来处理输入的词嵌入，LSTM迭代的次数与词个个数一致"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tjUVOj6A1Ck",
        "outputId": "c25e0880-2da2-4dd0-ce65-b2391fa1d265"
      },
      "source": [
        "model = tf.keras.Sequential()\r\n",
        "# input_dim是词典大小， output_dim是词嵌入维度\r\n",
        "model.add(layers.Embedding(input_dim=1000,output_dim=64))\r\n",
        "# 添加lstm层，其会输出最后一个时间步的输出\r\n",
        "model.add(layers.LSTM(128))\r\n",
        "model.add(layers.Dense(10,activation='softmax'))\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 164,106\n",
            "Trainable params: 164,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDbDi7dwCm86"
      },
      "source": [
        "## 2 输出和状态\r\n",
        "\r\n",
        "默认情况下RNN层输出最后一个时间步的输出，输出的形状为(batch_size, units), 其中unit是传给层的构造参数。 如果要返回rnn每个时间步的序列，需要置return_sequence=True, 此时输出的形状为(batch_size, time_steps, units)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBgVCnJfClIA",
        "outputId": "c7815019-5990-459c-f023-e7a8c377e409"
      },
      "source": [
        "model = tf.keras.Sequential()\r\n",
        "model.add(layers.Embedding(input_dim=1000, output_dim=64))\r\n",
        "# 返回整个rnn序列的输出\r\n",
        "model.add(layers.GRU(128, return_sequences=True))\r\n",
        "model.add(layers.SimpleRNN(128))\r\n",
        "model.add(layers.Dense(10, activation='softmax'))\r\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, None, 128)         74496     \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 172,682\n",
            "Trainable params: 172,682\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VJDRK_PDYyL"
      },
      "source": [
        "\r\n",
        "RNN层可以返回最后一个时间步的状态。\r\n",
        "\r\n",
        "返回的状态可以用于恢复RNN或初始化另一个RNN。此设置通常在seq2seq模型中用到，其将编码器的最终状态作为解码器的初始状态。\r\n",
        "\r\n",
        "要使RNN层返回最终的状态需要在创建图层时置return_state=True。请注意，LSTM有两个状态向量，而GRU只有一个。\r\n",
        "\r\n",
        "要配置图层的初始状态， 需要网络构建中传入initial_state。其中状态的维度必须与图层的unit大小一样。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yR02vF9BDjSG",
        "outputId": "c83bb3c3-ad5a-45de-fde9-95ea9e5cc417"
      },
      "source": [
        "encoder_vocab = 1000\r\n",
        "decoder_vocab = 2000\r\n",
        "\r\n",
        "#编码层\r\n",
        "encode_input = layers.Input(shape=(None,))\r\n",
        "encode_emb = layers.Embedding(input_dim= encoder_vocab,output_dim=64)(encode_input)\r\n",
        "#同时返回状态\r\n",
        "encode_out,state_h, state_c = layers.LSTM(64,return_state=True,name='encoder')(encode_emb)\r\n",
        "encode_state = [state_h,state_c]\r\n",
        "\r\n",
        "# 解码层\r\n",
        "decode_input =layers.Input(shape=(None, ))\r\n",
        "decode_emb = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(decode_input)\r\n",
        "# 编码器的最终状态， 作为解码器的初始状态\r\n",
        "decode_out = layers.LSTM(64, name='decoder')(decode_emb, initial_state=encode_state)\r\n",
        "output = layers.Dense(10, activation='softmax')(decode_out)\r\n",
        "\r\n",
        "model = tf.keras.Model([encode_input, decode_input], output)\r\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 64)     64000       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, None, 64)     64000       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "encoder (LSTM)                  [(None, 64), (None,  33024       embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "decoder (LSTM)                  (None, 64)           33024       embedding_3[0][0]                \n",
            "                                                                 encoder[0][1]                    \n",
            "                                                                 encoder[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           650         decoder[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 194,698\n",
            "Trainable params: 194,698\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyFzZ2u9FCnS"
      },
      "source": [
        "## 3 RNN层和RNN Cell\r\n",
        "除了内置的RNN层以外， RNN API还提供单元级API。与可以处理整批次的输入序列不同， RNN Cell仅能处理单个时间步的数据。 如果想处理整批次的输入数据，需要将RNN Cell包含在tf.keras.layers.RNN中， 如：RNN(LSTMCell(10)\r\n",
        "\r\n",
        "同效果上说， RNN(LSTMCell(10))等价于LSTM(10)。但内置的GRU和LSTM层可以使用CuDNN，以提高计算性能。\r\n",
        "\r\n",
        "下面是三个内置的RNN单元， 以及其对应的RNN层。\r\n",
        "\r\n",
        "+ tf.keras.layers.SimpleRNNCell对应于SimpleRNN图层。\r\n",
        "+ tf.keras.layers.GRUCell对应于GRU图层。\r\n",
        "+ tf.keras.layers.LSTMCell对应于LSTM图层。\r\n",
        "注： tf.keras.layers.RNN类可以使为研究实现自定义RNN体系结构变得非常容易"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lACbNtmzFQAz",
        "outputId": "6c73b5b9-ee75-4d1b-9047-16d0a0e08465"
      },
      "source": [
        "model = tf.keras.Sequential()\r\n",
        "# input_dim是词典大小， output_dim是词嵌入维度\r\n",
        "model.add(layers.Embedding(input_dim=1000, output_dim=64))\r\n",
        "# 添加lstm层，其会输出最后一个时间步的输出\r\n",
        "model.add(layers.RNN(layers.LSTMCell(64)))\r\n",
        "model.add(layers.Dense(10, activation='softmax'))\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, None, 64)          64000     \n",
            "_________________________________________________________________\n",
            "rnn (RNN)                    (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 97,674\n",
            "Trainable params: 97,674\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL5PQPaBGBW6"
      },
      "source": [
        "## 4 跨批次状态\r\n",
        "在处理超长序列（有可能无限长）时，可能需要使用到跨批次状态的模式。\r\n",
        "\r\n",
        "通常，每次看到新的批次时， 都会重置RNN层的内部状态（state，非权重。即该层看到的每个样本都独立于过去）。\r\n",
        "\r\n",
        "但，当序列过长，需要分不同批次输入时，则无需重置RNN的状态(上一批的结束状态，为下一批的初始状态)。这样，即使一次只看到一个子序列，网络层也可以保留整个序列的信息。\r\n",
        "\r\n",
        "我们可以置state_ful=True来设置跨批次状态。\r\n",
        "\r\n",
        "如果有序列s = [t0, t1, ... t1546, t1547]， 可以将其分为以下批次数据：\r\n",
        "\r\n",
        "s1 = [t0, t1, ... t100]\r\n",
        "\r\n",
        "s2 = [t101, ... t201]\r\n",
        "\r\n",
        "...\r\n",
        "\r\n",
        "16 = [t1501, ... t1547]\r\n",
        "\r\n",
        "具体调用方法如下："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V6BEsVcGLO3"
      },
      "source": [
        "sub_sequence = []\r\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\r\n",
        "for s in sub_sequence:\r\n",
        "    output = lstm_layer(s)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS4vRAtZGRcO"
      },
      "source": [
        "\r\n",
        "要清除状态时，可以使用layer.reset_states()。\r\n",
        "\r\n",
        "注意：在此设置中，i假定给定批次中的样品i是上一个批次中样品的延续。这意味着所有批次应包含相同数量的样本（批次大小）。例如，如果一个批次包含[sequence_A_from_t0_to_t100, sequence_B_from_t0_to_t100]，则下一个批次应包含[sequence_A_from_t101_to_t200, sequence_B_from_t101_to_t200]。\r\n",
        "\r\n",
        "跨批次状态例子"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPVxS9NrGSec"
      },
      "source": [
        "para1 = np.random.random((20, 10, 50)).astype(np.float32)\r\n",
        "para2 = np.random.random((20, 10, 50)).astype(np.float32)\r\n",
        "para3 = np.random.random((20, 10, 50)).astype(np.float32)\r\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\r\n",
        "output = lstm_layer(para1)\r\n",
        "output = lstm_layer(para2)\r\n",
        "output = lstm_layer(para3)\r\n",
        "lstm_layer.reset_states()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KiNn_jgHAEJ"
      },
      "source": [
        "## 5 双向LSTM\r\n",
        "对于时间序列以外的序列，比如文本，RNN不仅可以正向处理序列，也可以反向处理序列。例如要预测句子的某个单纯，上下文对单词都有用。\r\n",
        "\r\n",
        "Keras提供了tf.keras.layers.Bidirectional的API，构建双向RNN。\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4AlV8faHaKf",
        "outputId": "14499e2d-3035-471f-aae8-02f69666741e"
      },
      "source": [
        "model = tf.keras.Sequential()\r\n",
        "model.add(layers.Bidirectional(layers.LSTM(64, return_sequences=True),\r\n",
        "                              input_shape=(5, 10)))\r\n",
        "model.add(layers.Bidirectional(layers.LSTM(32)))\r\n",
        "model.add(layers.Dense(10, activation='softmax'))\r\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional (Bidirectional (None, 5, 128)            38400     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 64)                41216     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 80,266\n",
            "Trainable params: 80,266\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dcz1f37HmaG"
      },
      "source": [
        "在内部， Bidirectional将复制传入的RNN，并将逆序输入新复制的RNN，并输出前向输出和后向输出的叠加。如果想要其他合并行为（如串联），可以修改merge_mode等参数。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGvVYegHHoXa"
      },
      "source": [
        "## 6 TensorFlow2.0中的性能优化和CuDNN内核\r\n",
        "在TensorFlow2.0中，内置的LSTM和GRU层已更新，已在有GPU时默认使用CuDNN内核。通过此更改，先前的keras.layers.CuDNNLSTM/CuDNNGRU层已经弃用，可以简易的构建模型而不必担心其运行的硬件。\r\n",
        "\r\n",
        "由于CuDNN内核是根据某些假设构建的，因此如果改变内置LSTM或GRU的默认设置，则该层无法使用CuDNN内核，例如:\r\n",
        "\r\n",
        "+ 将activation从tanh改为其他激活函数。\r\n",
        "+ 将recurrent_activation由sigmoid改为其他激活函数。\r\n",
        "+ 使recurrent_dropout> 0。\r\n",
        "+ 设置unroll为True，将强制LSTM / GRU将内部分解tf.while_loop为展开的for循环。\r\n",
        "+ 设置use_bias为False。\r\n",
        "+当输入数据未严格右填充时使用掩蔽（如果掩码对应于严格右填充数据，则仍可以使用CuDNN。这是最常见的情况）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJxtMeEtH9dd"
      },
      "source": [
        "### 6.1 在可用时使用CuDNN内核\r\n",
        "我们构建一个简单的LSTM网络，来实现MNIST数字识别"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODPmsj_MHnrj"
      },
      "source": [
        "batch_size = 64\r\n",
        "input_dim = 28\r\n",
        "units = 64\r\n",
        "output_size = 10\r\n",
        "\r\n",
        "def build_model(allow_cudnn_kernel=True):\r\n",
        "    if allow_cudnn_kernel:\r\n",
        "        # LSTM默认cudnn加速\r\n",
        "        lstm_layer = tf.keras.layers.LSTM(units, input_shape=(None, input_dim))\r\n",
        "    else:\r\n",
        "        # LSTMCell内核没有使用\r\n",
        "        lstm_layer = tf.keras.layers.RNN(tf.keras.layers.LSTMCell(units),\r\n",
        "                                        input_shape=(None, input_dim))\r\n",
        "    model = tf.keras.models.Sequential([\r\n",
        "        lstm_layer,\r\n",
        "        tf.keras.layers.BatchNormalization(),\r\n",
        "        tf.keras.layers.Dense(output_size, activation='softmax')\r\n",
        "    ])\r\n",
        "    return model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7cllbIKIMQn"
      },
      "source": [
        "加载MNIST数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjEye2ZyIOn4",
        "outputId": "d73058c4-2fcb-4d44-a5a9-ba464be6055b"
      },
      "source": [
        "\r\n",
        "mnits = tf.keras.datasets.mnist\r\n",
        "\r\n",
        "(x_train, y_train), (x_test, y_test) = mnits.load_data()\r\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\r\n",
        "sample, sample_label = x_train[0], y_train[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Np1zxEuOITej"
      },
      "source": [
        "创建模型实例并进行编译"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0kJbAe4IUFT"
      },
      "source": [
        "model = build_model(allow_cudnn_kernel=True)\r\n",
        "model.compile(loss='sparse_categorical_crossentropy',\r\n",
        "             optimizer='sgd',\r\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aedka3h8IZol",
        "outputId": "80770e2d-b599-42b4-c5a1-0f802a324b28"
      },
      "source": [
        "\r\n",
        "# 使用cudnn的训练\r\n",
        "model.fit(x_train, y_train,\r\n",
        "         validation_data=(x_test, y_test),\r\n",
        "         batch_size=batch_size,\r\n",
        "         epochs=2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "938/938 [==============================] - 23s 22ms/step - loss: 1.3248 - accuracy: 0.5690 - val_loss: 0.5004 - val_accuracy: 0.8485\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 19s 21ms/step - loss: 0.4129 - accuracy: 0.8772 - val_loss: 0.2565 - val_accuracy: 0.9209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4ec084ea90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlItWmzhIrkY",
        "outputId": "0003c707-b7d8-459f-9924-336b0b24c10f"
      },
      "source": [
        "#在没有CuDNN内核的情况下构建新模型\r\n",
        "slow_model = build_model(allow_cudnn_kernel=False)\r\n",
        "#slow_model.set_weights(model.get_weights())\r\n",
        "slow_model.compile(loss='sparse_categorical_crossentropy',\r\n",
        "             optimizer='sgd',\r\n",
        "             metrics=['accuracy'])\r\n",
        "slow_model.fit(x_train, y_train,\r\n",
        "              validation_data=(x_test, y_test),\r\n",
        "              batch_size=batch_size,\r\n",
        "              epochs=2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "938/938 [==============================] - 20s 21ms/step - loss: 1.3102 - accuracy: 0.5747 - val_loss: 0.4920 - val_accuracy: 0.8502\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 19s 20ms/step - loss: 0.4142 - accuracy: 0.8773 - val_loss: 0.5033 - val_accuracy: 0.8248\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4eb543e320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "nCkd-l2XI3OQ",
        "outputId": "5b5360f0-3081-4880-8efe-db96e2af5c0b"
      },
      "source": [
        "# 使用cudnn的模型也可以在cpu环境中进行推理\r\n",
        "\r\n",
        "with tf.device('CPU:0'):\r\n",
        "    cpu_model = build_model(allow_cudnn_kernel=True)\r\n",
        "    cpu_model.set_weights(model.get_weights())\r\n",
        "    result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\r\n",
        "    print('预测结果: %s, 正确标签: %s' % (result.numpy(), sample_label))\r\n",
        "    plt.imshow(sample, cmap=plt.get_cmap('gray'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "预测结果: [5], 正确标签: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AJjAYJMJWLM"
      },
      "source": [
        "\r\n",
        "## 7.具有列表/字典输入或嵌套输入的RNN\r\n",
        "嵌套结构可以在单个时间步内包含更多信息。例如，一个视频帧可以同时具有音频和视频输入。比如以下的数据格式：\r\n",
        "\r\n",
        "[batch, timestep, {\"video\": [height, width, channel], \"audio\": [frequency]}]\r\n",
        "\r\n",
        "另一个例子，如笔迹数据。可以有当前的位置坐标x，y和压力信息。格式如下：\r\n",
        "\r\n",
        "[batch, timestep, {\"location\": [x, y], \"pressure\": [force]}]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJZmSDH8KBaa"
      },
      "source": [
        "7.1 定义一个支持嵌套输入/输出的自定义单元格"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRTp7mh2KCIJ"
      },
      "source": [
        "NestedInput = collections.namedtuple('NestedInput', ['feature1', 'feature2'])\r\n",
        "NestedState = collections.namedtuple('NestedState', ['state1', 'state2'])\r\n",
        "\r\n",
        "class NestedCell(tf.keras.layers.Layer):\r\n",
        "    # 初始化，获取相关参数\r\n",
        "    def __init__(self,unit1, unit2, unit3, **kwargs):\r\n",
        "        self.unit1 = unit1\r\n",
        "        self.unit2 = unit2\r\n",
        "        self.unit3 = unit3\r\n",
        "        self.state_size = NestedState(state1=unit1,\r\n",
        "                                     state2=tf.TensorShape([unit2, unit3]))\r\n",
        "        \r\n",
        "        self.output_size = (unit1, tf.TensorShape([unit2, unit3]))\r\n",
        "        super(NestedCell, self).__init__(**kwargs)\r\n",
        "    # 构建权重、网络\r\n",
        "    def build(self, input_shapes):\r\n",
        "        # input_shape包含2个特征项 [(batch, i1), (batch, i2, i3)]\r\n",
        "        input1 = input_shapes.feature1[1]\r\n",
        "        input2, input3 = input_shapes.feature2[1:]\r\n",
        "        \r\n",
        "        self.kernel_1 = self.add_weight(\r\n",
        "            shape=(input1, self.unit1), initializer='uniform', name='kernel_1'\r\n",
        "        )\r\n",
        "        self.kernel_2_3 = self.add_weight(\r\n",
        "            shape=(input2, input3, self.unit2, self.unit3),\r\n",
        "            initializer='uniform',\r\n",
        "            name='kernel_2_3'\r\n",
        "        )\r\n",
        "    # 前向连接网络\r\n",
        "    def call(self, inputs, states):\r\n",
        "        # inputs: [(batch, input_1), (batch, input_2, input_3)]\r\n",
        "        # state: [(batch, unit_1), (batch, unit_2, unit_3)]\r\n",
        "        input1, input2 = tf.nest.flatten(inputs)\r\n",
        "        s1, s2 = states\r\n",
        "        \r\n",
        "        output_1 = tf.matmul(input1, self.kernel_1)\r\n",
        "        output_2_3 = tf.einsum('bij,ijkl->bkl', input2, self.kernel_2_3)\r\n",
        "        \r\n",
        "        state_1 = s1 + output_1\r\n",
        "        state_2_3 = s2 + output_2_3\r\n",
        "        \r\n",
        "        output = [output_1, output_2_3]\r\n",
        "        new_states = NestedState(state1=state_1, state2=state_2_3)\r\n",
        "        return output, new_states"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcOUaF-tKtLl"
      },
      "source": [
        "7.2 使用嵌套的输入输出构建RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ho4BHv7cKvYj"
      },
      "source": [
        "unit_1 = 10\r\n",
        "unit_2 = 20\r\n",
        "unit_3 = 30\r\n",
        "\r\n",
        "input_1 = 32\r\n",
        "input_2 = 64\r\n",
        "input_3 = 32\r\n",
        "batch_size = 64\r\n",
        "num_batch = 100\r\n",
        "timestep = 50\r\n",
        "cell = NestedCell(unit_1, unit_2, unit_3)\r\n",
        "rnn = tf.keras.layers.RNN(cell)\r\n",
        "input1 = tf.keras.Input((None, input_1))\r\n",
        "input2 = tf.keras.Input((None, input_2, input_3))\r\n",
        "outputs = rnn(NestedInput(feature1=input1, feature2=input2))\r\n",
        "model = tf.keras.models.Model([input1, input2], outputs)\r\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oKdFr09Kzoi"
      },
      "source": [
        "构造数据训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsV6mKV_KxOB",
        "outputId": "fd71433b-de0d-4743-9168-7ac4b7af6d6a"
      },
      "source": [
        "input_1_data = np.random.random((batch_size * num_batch, timestep, input_1))\r\n",
        "input_2_data = np.random.random((batch_size * num_batch, timestep, input_2, input_3))\r\n",
        "target_1_data = np.random.random((batch_size * num_batch, unit_1))\r\n",
        "target_2_data = np.random.random((batch_size * num_batch, unit_2, unit_3))\r\n",
        "input_data = [input_1_data, input_2_data]\r\n",
        "target_data = [target_1_data, target_2_data]\r\n",
        "\r\n",
        "model.fit(input_data, target_data, batch_size=batch_size)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 64s 634ms/step - loss: 0.5229 - rnn_2_loss: 0.1883 - rnn_2_1_loss: 0.3346 - rnn_2_accuracy: 0.1028 - rnn_2_1_accuracy: 0.0327\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4eb460b6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}